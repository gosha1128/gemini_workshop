# coding: utf-8

"""
    GSI Floating-Point 32 API

    **Introduction**<br> GSI Technology’s floating-point similarity search API provides an accessible gateway to running searches on GSI’s Gemini® Associative Processing Unit (APU).<br> It works in conjunction with the GSI system management solution which enables users to work with multiple APU boards simultaneously for improved performance.<br><br> **Dataset and Query Format**<br> Dataset embeddings can be in 32- or 64-bit floating point format, and any number of features, e.g. 256 or 512 (there is no upper limit).<br> Query embeddings must have the same floating-point format and number of features as used in the dataset.<br> GSI performs the search and delivers the top-k most similar results.  # noqa: E501

    OpenAPI spec version: 1.0
    
    Generated by: https://github.com/swagger-api/swagger-codegen.git
"""

import pprint
import re  # noqa: F401

import six

class ImportDatasetRequest(object):
    """NOTE: This class is auto generated by the swagger code generator program.

    Do not edit the class manually.
    """
    """
    Attributes:
      swagger_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    swagger_types = {
        'ds_file_path': 'str',
        'train_ind': 'bool',
        'train_config_file_path': 'str',
        'search_type': 'str',
        'target_accuracy': 'float',
        'md_file_path': 'str'
    }

    attribute_map = {
        'ds_file_path': 'dsFilePath',
        'train_ind': 'trainInd',
        'train_config_file_path': 'trainConfigFilePath',
        'search_type': 'searchType',
        'target_accuracy': 'targetAccuracy',
        'md_file_path': 'mdFilePath'
    }

    def __init__(self, ds_file_path=None, train_ind=False, train_config_file_path=None, search_type='flat', target_accuracy=100, md_file_path=None):  # noqa: E501
        """ImportDatasetRequest - a model defined in Swagger"""  # noqa: E501
        self._ds_file_path = None
        self._train_ind = None
        self._train_config_file_path = None
        self._search_type = None
        self._target_accuracy = None
        self._md_file_path = None
        self.discriminator = None
        self.ds_file_path = ds_file_path
        if train_ind is not None:
            self.train_ind = train_ind
        if train_config_file_path is not None:
            self.train_config_file_path = train_config_file_path
        if search_type is not None:
            self.search_type = search_type
        if target_accuracy is not None:
            self.target_accuracy = target_accuracy
        if md_file_path is not None:
            self.md_file_path = md_file_path

    @property
    def ds_file_path(self):
        """Gets the ds_file_path of this ImportDatasetRequest.  # noqa: E501

        Path to file representing the dataset records.<br> File format should be .npy  # noqa: E501

        :return: The ds_file_path of this ImportDatasetRequest.  # noqa: E501
        :rtype: str
        """
        return self._ds_file_path

    @ds_file_path.setter
    def ds_file_path(self, ds_file_path):
        """Sets the ds_file_path of this ImportDatasetRequest.

        Path to file representing the dataset records.<br> File format should be .npy  # noqa: E501

        :param ds_file_path: The ds_file_path of this ImportDatasetRequest.  # noqa: E501
        :type: str
        """
        if ds_file_path is None:
            raise ValueError("Invalid value for `ds_file_path`, must not be `None`")  # noqa: E501

        self._ds_file_path = ds_file_path

    @property
    def train_ind(self):
        """Gets the train_ind of this ImportDatasetRequest.  # noqa: E501

        Flag that indicates whether a dataset should be trained.  # noqa: E501

        :return: The train_ind of this ImportDatasetRequest.  # noqa: E501
        :rtype: bool
        """
        return self._train_ind

    @train_ind.setter
    def train_ind(self, train_ind):
        """Sets the train_ind of this ImportDatasetRequest.

        Flag that indicates whether a dataset should be trained.  # noqa: E501

        :param train_ind: The train_ind of this ImportDatasetRequest.  # noqa: E501
        :type: bool
        """

        self._train_ind = train_ind

    @property
    def train_config_file_path(self):
        """Gets the train_config_file_path of this ImportDatasetRequest.  # noqa: E501

        Path to a custom training configuration file.  # noqa: E501

        :return: The train_config_file_path of this ImportDatasetRequest.  # noqa: E501
        :rtype: str
        """
        return self._train_config_file_path

    @train_config_file_path.setter
    def train_config_file_path(self, train_config_file_path):
        """Sets the train_config_file_path of this ImportDatasetRequest.

        Path to a custom training configuration file.  # noqa: E501

        :param train_config_file_path: The train_config_file_path of this ImportDatasetRequest.  # noqa: E501
        :type: str
        """

        self._train_config_file_path = train_config_file_path

    @property
    def search_type(self):
        """Gets the search_type of this ImportDatasetRequest.  # noqa: E501

        Flag indicates if the dataset search type will be clustered or flat.  # noqa: E501

        :return: The search_type of this ImportDatasetRequest.  # noqa: E501
        :rtype: str
        """
        return self._search_type

    @search_type.setter
    def search_type(self, search_type):
        """Sets the search_type of this ImportDatasetRequest.

        Flag indicates if the dataset search type will be clustered or flat.  # noqa: E501

        :param search_type: The search_type of this ImportDatasetRequest.  # noqa: E501
        :type: str
        """
        allowed_values = ["flat", "clusters"]  # noqa: E501
        if search_type not in allowed_values:
            raise ValueError(
                "Invalid value for `search_type` ({0}), must be one of {1}"  # noqa: E501
                .format(search_type, allowed_values)
            )

        self._search_type = search_type

    @property
    def target_accuracy(self):
        """Gets the target_accuracy of this ImportDatasetRequest.  # noqa: E501

        Expected accuracy for optimal Hamming K calculation.  # noqa: E501

        :return: The target_accuracy of this ImportDatasetRequest.  # noqa: E501
        :rtype: float
        """
        return self._target_accuracy

    @target_accuracy.setter
    def target_accuracy(self, target_accuracy):
        """Sets the target_accuracy of this ImportDatasetRequest.

        Expected accuracy for optimal Hamming K calculation.  # noqa: E501

        :param target_accuracy: The target_accuracy of this ImportDatasetRequest.  # noqa: E501
        :type: float
        """

        self._target_accuracy = target_accuracy

    @property
    def md_file_path(self):
        """Gets the md_file_path of this ImportDatasetRequest.  # noqa: E501

        Path to a metadata file which will be associated with the dataset.  # noqa: E501

        :return: The md_file_path of this ImportDatasetRequest.  # noqa: E501
        :rtype: str
        """
        return self._md_file_path

    @md_file_path.setter
    def md_file_path(self, md_file_path):
        """Sets the md_file_path of this ImportDatasetRequest.

        Path to a metadata file which will be associated with the dataset.  # noqa: E501

        :param md_file_path: The md_file_path of this ImportDatasetRequest.  # noqa: E501
        :type: str
        """

        self._md_file_path = md_file_path

    def to_dict(self):
        """Returns the model properties as a dict"""
        result = {}

        for attr, _ in six.iteritems(self.swagger_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value
        if issubclass(ImportDatasetRequest, dict):
            for key, value in self.items():
                result[key] = value

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, ImportDatasetRequest):
            return False

        return self.__dict__ == other.__dict__

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        return not self == other
